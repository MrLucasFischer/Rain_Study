---
title: "rain_study"
author: "L.Fischer"
date: "7/30/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Rain Study

This is an R Markdown script containing my study on the Australian Rain dataset, which can be found [here](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package).

I'll start off by loading the needed libraries and importing the dataset

```{r libs, message=FALSE, warning=FALSE}
library(tidyverse)
library(GGally)

data = read_csv("../input/weatherAUS.csv")
dim(data)
```

Checking a small portion of the dataset

```{r}
head(data)
```

We can factorize some of the columns that make sense to do it
```{r}
data = data %>% 
    mutate_at(vars(Location, WindGustDir, WindDir9am, WindDir3pm, RainToday, RainTomorrow), as.factor)
```

We can see by the output of the `head` function that columns `Evaporation`, `Sunshine` and some others appear to have a lot of missing values. It's important to check how many missing values are in each column.
For that we just summarise each column as the sum of the number of missing values in them (I'm transposing the result tibble so that it's possible to see all variables at the same time)

```{r}
data %>%
    summarise_each(list(~ sum(is.na(.)) / length(.) * 100)) %>%
    t()
```

We clearly see that the most alarming columns are `Evaporation`, `Sunshine`, which have around 98% of missing values, I guess someone forgot to register these variables :). `Cloud9am` and `Cloud3pm` are possibly problamatic as well so we'll remove these columns too.

For the rest of the columns we have to make some decisions. We can try to replace the missing values with the means of each column (or with any other technique we see fit) but that might bias our study. Another possibility might be to delete the rows in each a column has a missing value. These remaining columns have a relative low percentage of missing values, but it might be that all missing values are from examples of one of the classes (for example the class of observations in each it rained the next day, the class of interest) and so removing might make us lose valuable information for that class. We'll go with this decision (because I'm lazy and this is simpler (: ). But first let's check to see the percentage of missing values for each column and for each class to make sure we're not removing valuable information.

To do this we can run the exact same computation as before, just grouping by our dependent variable `RainTomorrow` (Note that I'm already removing the columns discussed before)

```{r}
data = data %>% select(-Evaporation, -Sunshine, -Cloud9am, -Cloud3pm)

data %>%
    group_by(RainTomorrow) %>%
    summarise_each(list(~ sum(is.na(.)) / length(.) * 100)) %>%
    t()
```

Great, nothing that alarming! We can simply remove rows with missing values and we're all set!

```{r}
data = data %>% na.exclude()
```